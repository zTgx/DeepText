# DeepText: A GPT model to generate text

This is a hands-on exploration of Transformer architectures, featuring a from-scratch PyTorch implementation of a GPT-style model. Designed as a learning journey, the project prioritizes understanding core mechanisms over production use, with iterative updates as knowledge deepens.

## Key features:

* Pure PyTorch implementation
* Focus on Transformer internals
* Living codebase (continuous improvements)